#!/bin/bash

OUTPUT_DIR=/data/teamdata/shared/system

#start clean
rm -f /tmp/measurements.csv
#get the full data
#FIXME: are those all the columns?
psql -U deploy -h ec2-50-112-49-143.us-west-2.compute.amazonaws.com teamdata -c "\copy (select captured_at, ST_Y(location::geometry), ST_X(location::geometry), value, unit, location_name, device_id, md5sum, height, surface, radiation, created_at, measurement_import_id from measurements order by created_at desc) to '/tmp/measurements.csv' csv;"

# TODO: Once it is confirmed that (mostly) noone uses the tar.bz file, will remove the next lines till __END__TODO__
#add header
echo "Captured Time,Latitude,Longitude,Value,Unit,Location Name,Device ID,MD5Sum,Height,Surface,Radiation,Uploaded Time,Loader ID" | cat - /tmp/measurements.csv > ${OUTPUT_DIR}/measurements-out.csv
cd ${OUTPUT_DIR} && tar -czf measurements-out.tar.gz measurements-out.csv
mv measurements-out.tar.gz measurements.tar.gz && mv measurements-out.csv measurements.csv
#
# Now this is available as https://api.safecast.org/system/measurements.tar.gz
#
# __END__TODO__

# FIXME: do we need to provide uncompressed CSV? If so, add a `tee`
# FIXME: is Apache somehow using the gz file to serve compressed content? If not, bzip2 compresses better
#add header and gzip the result in the fly
echo "Captured Time,Latitude,Longitude,Value,Unit,Location Name,Device ID,MD5Sum,Height,Surface,Radiation,Uploaded Time,Loader ID" | cat - /tmp/measurements.csv |bzip2 - > ${OUTPUT_DIR}/measurements.csv.bz2
#end clean
rm -f /tmp/measurements.csv
#
# You can get this at https://api.safecast.org/system/measurements.csv.bz2
#

